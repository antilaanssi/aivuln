{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebc9f4-1e8d-46b0-b68f-12cda41c1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install adversarial-robustness-toolbox\n",
    "#!pip install torch\n",
    "#!pip install pytorchyolo\n",
    "#!pip install pillow\n",
    "#!pip install numpy --upgrade\n",
    "#!pip install detr\n",
    "#!pip install --upgrad matplotlib\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9dabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall fiftyone -y\n",
    "#!pip install fiftyone==0.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37aa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "flag=0\n",
    "while flag!=1:\n",
    "    try:\n",
    "        import fiftyone as fo\n",
    "        flag=1\n",
    "        print(\"success\")\n",
    "    except Exception as e:\n",
    "        print(\"failed, retrying\")\n",
    "        time.sleep(1)\n",
    "        flag=0\n",
    "        print(e)\n",
    "    \n",
    "import fiftyone.zoo as foz\n",
    "print(\"second import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f59977-563a-4fd0-b241-7db8d1978daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.object_detection.pytorch_detection_transformer import PyTorchDetectionTransformer\n",
    "from art.attacks.evasion.adversarial_patch.adversarial_patch_pytorch import AdversarialPatchPyTorch\n",
    "from art.estimators.object_detection.pytorch_yolo import PyTorchYolo\n",
    "\n",
    "from art.attacks.evasion import RobustDPatch\n",
    "from torchvision.transforms import transforms\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import detr\n",
    "from tqdm import tqdm\n",
    "print(\"first import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d8c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3cbd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if gpu is available:\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "\n",
    "torch.cuda.current_device()\n",
    "\n",
    "\n",
    "torch.cuda.device(0)\n",
    "\n",
    "torch.cuda.get_device_name(0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fecb1a-f5b1-497f-8a2a-598aa7a3a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "        'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', \n",
    "        'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "COCO_CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d09e89-51bb-4a0f-a692-0608017736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"555544433222211221221232323232223232313232211\"\n",
    "dataset_dir=\"./coco_resized/validation/\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset.persistent = False\n",
    "predictions_view = dataset.take(50, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f454e1f-ffe1-49ec-a725-8de1964dacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_boxes(predictions, conf_thresh):\n",
    "    dictionary = {}\n",
    "\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for i in range(len(predictions[0][\"boxes\"])):\n",
    "        score = predictions[0][\"scores\"][i]\n",
    "        if score >= conf_thresh:\n",
    "            boxes_list.append(predictions[0][\"boxes\"][i])\n",
    "            scores_list.append(predictions[0][\"scores\"][[i]])\n",
    "            labels_list.append(predictions[0][\"labels\"][[i]])\n",
    "\n",
    "    dictionary[\"boxes\"] = np.vstack(boxes_list)\n",
    "    dictionary[\"scores\"] = np.hstack(scores_list)\n",
    "    dictionary[\"labels\"] = np.hstack(labels_list)\n",
    "\n",
    "    y = [dictionary]\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(predictions_, conf_thresh):\n",
    "    predictions_class = [COCO_CLASSES[i] for i in list(predictions_[\"labels\"])]\n",
    "    if len(predictions_class) < 1:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
    "    predictions_score = list(predictions_[\"scores\"])\n",
    "\n",
    "    threshold = conf_thresh\n",
    "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold]\n",
    "    if len(predictions_t) > 0:\n",
    "        predictions_t = predictions_t\n",
    "    else:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [predictions_boxes[i] for i in predictions_t]\n",
    "    predictions_class = [predictions_class[i] for i in predictions_t]\n",
    "    predictions_scores = [predictions_score[i] for i in predictions_t]\n",
    "    return predictions_class, predictions_boxes, predictions_scores\n",
    "def plot_image_with_boxes(img, boxes, pred_cls, title):\n",
    "    text_size = 2\n",
    "    text_th = 2\n",
    "    rect_th = 2\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
    "                      color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img, pred_cls[i], (int(boxes[i][0][0]), int(boxes[i][0][1])), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                    (0, 255, 0), thickness=text_th)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c6344-bcb4-4698-862f-03d422156a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NUMBER_CHANNELS = 3\n",
    "INPUT_SHAPE = (3, 800, 800)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(INPUT_SHAPE[1], interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(INPUT_SHAPE[1]),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = PyTorchDetectionTransformer(channels_first=True, preprocessing=(MEAN, STD), input_shape=INPUT_SHAPE, clip_values=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40241343-c417-49d8-bc9f-df19ccc95897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers(filename):\n",
    "   numbers = re.findall(r'\\d+', filename)\n",
    "   return ''.join(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a2fd5-6f3e-4965-83d4-246961d85f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "image_ids = []\n",
    "image_sizes = []\n",
    "unsized_images = []\n",
    "import PIL\n",
    "import os\n",
    "for sample in predictions_view:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "    image_ids.append(image_id)\n",
    "    \n",
    "    im = PIL.Image.open(sample.filepath)\n",
    "        \n",
    "    \n",
    "    \n",
    "    im = im.convert('RGB')\n",
    "    image_sizes.append(im.size)\n",
    "    im = transform(im).numpy()\n",
    "    \n",
    "    coco_images.append(im)\n",
    "coco_images = np.array(coco_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dets = detector.predict(coco_images)    \n",
    "for i in range(len(dets)):\n",
    "    preds_orig = extract_predictions(dets[i], 0.5)\n",
    "    #if i%20 ==0:\n",
    "        #plot_image_with_boxes(img=coco_images[i].transpose(1,2,0).copy(), boxes=preds_orig[1], pred_cls=preds_orig[0], title=\"Predictions on image without patch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffc21b-2be2-46f9-8be5-801a49d16d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.attacks.evasion import DPatch\n",
    "print(\"Starting dpatch\")\n",
    "x = coco_images[:-1]\n",
    "\n",
    "dets = detector.predict(x)\n",
    "patch_shape = (3, 120, 120)\n",
    "\n",
    "attack = RobustDPatch(\n",
    "    detector,\n",
    "    patch_shape=patch_shape,\n",
    "    patch_location=(50, 50),\n",
    "    crop_range=[0,0],\n",
    "    brightness_range=[1.0, 1.0],\n",
    "    rotation_weights=[1, 0, 0, 0],\n",
    "    sample_size=1,\n",
    "    learning_rate=1.99,\n",
    "    max_iter=1,\n",
    "    batch_size=1,\n",
    "    verbose=False,\n",
    "    targeted=False\n",
    ")\n",
    "patch_shape = tuple(filter(lambda x: x != 3, patch_shape))\n",
    "\n",
    "# Convert tuple to string\n",
    "patch_shape = ''.join(map(str, patch_shape))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "for i in tqdm(range(500)):\n",
    "   patch = attack.generate(x)\n",
    "   patched_images = attack.apply_patch(x)\n",
    "\n",
    "\n",
    "_y = detector.predict(patched_images)\n",
    "\n",
    "\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height # ymax\n",
    "       ]\n",
    "\n",
    "        # Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "\n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "    plot_image_with_boxes(img=patched_images[i].transpose(1,2,0).copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions on image without patch\")\n",
    "    sample = dataset[f'/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg']\n",
    "\n",
    "    sample[\"detr\"] = fo.Detections(detections=detections)\n",
    "    sample.save()\n",
    "print(detections)\n",
    "#print(sample)\n",
    "print(\"finished adding predictions\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4a55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10da49-b640-4865-9e48-6f907a582050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb56e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predictions_view.filter_labels(\"detr\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9143176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.detr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11c746-bdd2-4fc0-be28-2107cdfa0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample.detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46db5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predictions_view.evaluate_detections(\n",
    "    \"detr\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"detr_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b51099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61cc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe34771",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"result.txt\", \"w\")\n",
    "#convert variable to string\n",
    "result = str(result)\n",
    "file.write(\"result = \" + result + \"\\n\")\n",
    "\n",
    "#close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf17d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716bb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86f710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "683e2910",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
