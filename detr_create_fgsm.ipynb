{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebc9f4-1e8d-46b0-b68f-12cda41c1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fiftyone\n",
    "#!pip install adversarial-robustness-toolbox\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f59977-563a-4fd0-b241-7db8d1978daa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.estimators.object_detection.pytorch_detection_transformer import PyTorchDetectionTransformer\n",
    "from art.attacks.evasion.adversarial_patch.adversarial_patch_pytorch import AdversarialPatchPyTorch\n",
    "from torchvision.transforms import transforms\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d09e89-51bb-4a0f-a692-0608017736d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset = foz.load_zoo_dataset(\n",
    " #   \"coco-resized-to-800\",\n",
    "  #  split=\"validation\",\n",
    "   # dataset_name=\"dpatched-images\",\n",
    "#)\n",
    "\n",
    "name=\"yolo-detr-transfer\"\n",
    "dataset_dir=\"./coco_resized/validation\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset.persistent = False\n",
    "predictions_view = dataset.take(50, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fecb1a-f5b1-497f-8a2a-598aa7a3a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f454e1f-ffe1-49ec-a725-8de1964dacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_boxes(predictions, conf_thresh):\n",
    "    dictionary = {}\n",
    "\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for i in range(len(predictions[0][\"boxes\"])):\n",
    "        score = predictions[0][\"scores\"][i]\n",
    "        if score >= conf_thresh:\n",
    "            boxes_list.append(predictions[0][\"boxes\"][i])\n",
    "            scores_list.append(predictions[0][\"scores\"][[i]])\n",
    "            labels_list.append(predictions[0][\"labels\"][[i]])\n",
    "\n",
    "    dictionary[\"boxes\"] = np.vstack(boxes_list)\n",
    "    dictionary[\"scores\"] = np.hstack(scores_list)\n",
    "    dictionary[\"labels\"] = np.hstack(labels_list)\n",
    "\n",
    "    y = [dictionary]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa39c18-fca3-405e-8f93-c20224e32329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(img, boxes, pred_cls, title, save, filename):\n",
    "    text_size = 2\n",
    "    text_th = 2\n",
    "    rect_th = 2\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
    "                      color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img, pred_cls[i], (int(boxes[i][0][0]), int(boxes[i][0][1])), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                    (0, 255, 0), thickness=text_th)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    if save == True and filename != None:\n",
    "       print(filename)\n",
    "       print(\"image saved\")\n",
    "       plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2bfac-2ac6-4599-ae4f-60ad6f47dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(predictions_, conf_thresh):\n",
    "    predictions_class = [COCO_CLASSES[i] for i in list(predictions_[\"labels\"])]\n",
    "    if len(predictions_class) < 1:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
    "    predictions_score = list(predictions_[\"scores\"])\n",
    "\n",
    "    threshold = conf_thresh\n",
    "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold]\n",
    "    if len(predictions_t) > 0:\n",
    "        predictions_t = predictions_t\n",
    "    else:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [predictions_boxes[i] for i in predictions_t]\n",
    "    predictions_class = [predictions_class[i] for i in predictions_t]\n",
    "    predictions_scores = [predictions_score[i] for i in predictions_t]\n",
    "    return predictions_class, predictions_boxes, predictions_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c6344-bcb4-4698-862f-03d422156a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NUMBER_CHANNELS = 3\n",
    "INPUT_SHAPE = (NUMBER_CHANNELS, 800, 800)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([INPUT_SHAPE[1], INPUT_SHAPE[2]], interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b2095-adfd-4263-86e1-698e72a9cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = PyTorchDetectionTransformer(channels_first=True, preprocessing=(MEAN, STD), input_shape=INPUT_SHAPE, clip_values=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40241343-c417-49d8-bc9f-df19ccc95897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers(filename):\n",
    "   numbers = re.findall(r'\\d+', filename)\n",
    "   return ''.join(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba09d23-24f5-4da6-a101-af84df282627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a2fd5-6f3e-4965-83d4-246961d85f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "coco_images = []\n",
    "image_ids = []\n",
    "image_sizes = []\n",
    "unsized_images = []\n",
    "from IPython.display import display\n",
    "\n",
    "for sample in predictions_view:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    #image_id = image_id.lstrip('0')\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "    image_ids.append(image_id)\n",
    "    im = PIL.Image.open(sample.filepath)\n",
    "    #display(im)\n",
    "\n",
    "    im = im.convert('RGB')\n",
    "    image_sizes.append(im.size)\n",
    "    #print(im.dtype) # Print the data type of the image\n",
    "    #print(f\"shape before: {im.shape}\")\n",
    "    im = transform(im).numpy()\n",
    "    #print(f\"shape after: {im.shape}\")\n",
    "    if im.shape != (3, 800, 800):\n",
    "        print(\"size doesn't match\")\n",
    "        print(im.shape)\n",
    "\n",
    "    coco_images.append(im)\n",
    "coco_images = np.array(coco_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073be357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_name = f\"run_images_{name}\"\n",
    "\n",
    "try:\n",
    "   os.makedirs(directory_name)\n",
    "except OSError as e:\n",
    "   if e.errno != errno.EEXIST:\n",
    "       raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a01fa-fc24-4f32-a208-d168621b08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dets = detector.predict(coco_images) \n",
    "for i in range(len(dets)):\n",
    "    preds_orig = extract_predictions(dets[i], 0.5)\n",
    "    plot_image_with_boxes(img=coco_images[i].transpose(1,2,0).copy(), boxes=preds_orig[1], pred_cls=preds_orig[0], title=\"Predictions on image without patch\", save=True, filename=f\"{directory_name}/benign{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffc21b-2be2-46f9-8be5-801a49d16d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "from IPython.display import Image\n",
    "attack = FastGradientMethod(detector,eps=0.01, batch_size=16) # tweakkaillaan epsiä tässä metodologiassa # max_iter 100 # 0.1\n",
    "\n",
    "\n",
    "attacked_images = []\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = coco_images\n",
    "adv = attack.generate(x)\n",
    "#np.save(f'{name}.npy', adv)\n",
    "adv = np.load(f'yolo_win__load_from_disk.npy') / 255\n",
    "\n",
    "_y = detector.predict(adv)\n",
    "\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height  # ymax\n",
    "       ]\n",
    "       # Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "    \n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       \n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "    print(i)\n",
    "    plot_image_with_boxes(img=adv[i].transpose(1,2,0).copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions attacked images\", save=True, filename=f\"{directory_name}/patched_image{i}\")\n",
    "    sample = dataset[f\"/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg\"]\n",
    "    sample[\"detr\"] = fo.Detections(detections=detections)\n",
    "    sample.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d796bf-fba9-4820-90d2-a55dbf608c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927c02d-a689-4266-bef9-73f0f958c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predictions_view.filter_labels(\"detr\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2100a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = high_conf_view.first()\n",
    "print(sample.detr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f27582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predictions_view.evaluate_detections(\n",
    "    \"detr\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"detr_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727da710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5773f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7fbdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{name}.txt\", \"w\")\n",
    "print(f\"saved as: {file}\")\n",
    "#convert variable to string\n",
    "result = str(result)\n",
    "file.write(\"result = \" + result + \"\\n\")\n",
    "\n",
    "#close file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d87595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
