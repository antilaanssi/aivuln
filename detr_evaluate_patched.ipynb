{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50a83385-3e3f-496a-9a61-ae3a4a0c74d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fiftyone in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (0.22.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (6.0.1)\n",
      "Requirement already satisfied: hypercorn>=0.13.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.15.0)\n",
      "Requirement already satisfied: kaleido!=0.2.1.post1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.2.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (2023.3.post1)\n",
      "Requirement already satisfied: packaging in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (23.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (4.12.2)\n",
      "Requirement already satisfied: dacite<1.8.0,>=1.6.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.7.0)\n",
      "Requirement already satisfied: starlette>=0.24.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.32.0.post1)\n",
      "Requirement already satisfied: Jinja2>=3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (3.1.2)\n",
      "Requirement already satisfied: fiftyone-db~=0.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.4.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (5.9.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (2.1.3)\n",
      "Requirement already satisfied: cachetools in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (5.3.2)\n",
      "Requirement already satisfied: strawberry-graphql==0.138.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.138.1)\n",
      "Requirement already satisfied: plotly>=4.14 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (5.18.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.22.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (4.8.1.78)\n",
      "Requirement already satisfied: pymongo>=3.12 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (4.6.0)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (58.1.0)\n",
      "Requirement already satisfied: pprintpp in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.4.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.9.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.3.4)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.2.14)\n",
      "Requirement already satisfied: sseclient-py<2,>=1.7.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.8.0)\n",
      "Requirement already satisfied: humanize in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (4.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.1.3)\n",
      "Requirement already satisfied: motor>=2.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (3.3.1)\n",
      "Requirement already satisfied: Pillow>=6.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (10.0.1)\n",
      "Requirement already satisfied: fiftyone-brain~=0.13.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.13.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.28.84)\n",
      "Requirement already satisfied: sse-starlette<1,>=0.10.3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.10.3)\n",
      "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.1.1)\n",
      "Requirement already satisfied: ftfy in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (6.1.1)\n",
      "Requirement already satisfied: aiofiles in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (23.2.1)\n",
      "Requirement already satisfied: mongoengine==0.24.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.24.2)\n",
      "Requirement already satisfied: regex in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (2023.10.3)\n",
      "Requirement already satisfied: voxel51-eta~=0.12 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (0.12.0)\n",
      "Requirement already satisfied: argcomplete in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone) (3.8.1)\n",
      "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from strawberry-graphql==0.138.1->fiftyone) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
      "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from strawberry-graphql==0.138.1->fiftyone) (4.8.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from fiftyone-brain~=0.13.2->fiftyone) (1.11.3)\n",
      "Requirement already satisfied: tomli in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n",
      "Requirement already satisfied: wsproto>=0.14.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (1.2.0)\n",
      "Requirement already satisfied: h11 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
      "Requirement already satisfied: taskgroup in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (0.0.0a4)\n",
      "Requirement already satisfied: h2>=3.1.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
      "Requirement already satisfied: priority in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from hypercorn>=0.13.2->fiftyone) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from Jinja2>=3->fiftyone) (2.1.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from plotly>=4.14->fiftyone) (8.2.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pymongo>=3.12->fiftyone) (2.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from starlette>=0.24.0->fiftyone) (4.0.0)\n",
      "Requirement already satisfied: httpx>=0.10.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.25.1)\n",
      "Requirement already satisfied: py7zr in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (0.20.7)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (2.0.7)\n",
      "Requirement already satisfied: dill in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (0.3.7)\n",
      "Requirement already satisfied: requests in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (1.16.0)\n",
      "Requirement already satisfied: jsonlines in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (4.0.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (2.4.0)\n",
      "Requirement already satisfied: glob2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (0.7)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (5.2)\n",
      "Requirement already satisfied: future in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (0.18.3)\n",
      "Requirement already satisfied: rarfile in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from voxel51-eta~=0.12->fiftyone) (4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from beautifulsoup4->fiftyone) (2.5)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.84 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from boto3->fiftyone) (1.31.84)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from boto3->fiftyone) (0.7.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from boto3->fiftyone) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from Deprecated->fiftyone) (1.14.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from ftfy->fiftyone) (0.2.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib->fiftyone) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib->fiftyone) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib->fiftyone) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib->fiftyone) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib->fiftyone) (4.44.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pandas->fiftyone) (2023.3)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-image->fiftyone) (2.32.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-image->fiftyone) (3.2.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-image->fiftyone) (2023.9.26)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-image->fiftyone) (0.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-learn->fiftyone) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-learn->fiftyone) (1.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.1.3)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (4.0.0)\n",
      "Requirement already satisfied: httpcore in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from jsonlines->voxel51-eta~=0.12->fiftyone) (23.1.0)\n",
      "Requirement already satisfied: texttable in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.7.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (0.15.9)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.1.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (3.19.0)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.0.0)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (0.2.3)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.0.2)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from py7zr->voxel51-eta~=0.12->fiftyone) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->voxel51-eta~=0.12->fiftyone) (3.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\anssi\\Desktop\\ai\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (4.36.0.dev0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->transformers) (2.0.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\anssi\\Desktop\\ai\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting super-gradients\n",
      "  Using cached super_gradients-3.5.0-py3-none-any.whl (12.0 MB)\n",
      "Collecting pyparsing==2.4.5\n",
      "  Using cached pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: scipy>=1.6.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (1.11.3)\n",
      "Collecting sphinx~=4.0.2\n",
      "  Using cached Sphinx-4.0.3-py3-none-any.whl (2.9 MB)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (0.16.0)\n",
      "Collecting termcolor==1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting sphinx-rtd-theme\n",
      "  Using cached sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Collecting protobuf==3.20.3\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: boto3>=1.17.15 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (1.28.84)\n",
      "Collecting pip-tools>=6.12.1\n",
      "  Using cached pip_tools-7.3.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: tensorboard>=2.4.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (2.15.1)\n",
      "Collecting treelib==1.6.1\n",
      "  Using cached treelib-1.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: pygments>=2.7.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (2.16.1)\n",
      "Collecting jsonschema>=3.2.0\n",
      "  Using cached jsonschema-4.20.0-py3-none-any.whl (84 kB)\n",
      "Collecting coverage~=5.3.1\n",
      "  Using cached coverage-5.3.1-py3-none-any.whl\n",
      "Collecting opencv-python>=4.5.1\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Collecting data-gradients~=0.3.1\n",
      "  Using cached data_gradients-0.3.1-py3-none-any.whl (459 kB)\n",
      "Collecting stringcase>=1.2.0\n",
      "  Using cached stringcase-1.2.0-py3-none-any.whl\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.5.2-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "Collecting json-tricks==3.16.1\n",
      "  Using cached json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting torchmetrics==0.8\n",
      "  Using cached torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
      "Collecting pycocotools==2.0.6\n",
      "  Using cached pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting onnx==1.13.0\n",
      "  Using cached onnx-1.13.0-cp310-cp310-win_amd64.whl (12.2 MB)\n",
      "Collecting einops==0.3.2\n",
      "  Using cached einops-0.3.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.9.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (2.1.0)\n",
      "Requirement already satisfied: Deprecated>=1.2.11 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (1.2.14)\n",
      "Collecting onnx-simplifier<1.0,>=0.4.3\n",
      "  Using cached onnx_simplifier-0.4.35-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "Collecting hydra-core>=1.2.0\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (58.1.0)\n",
      "Collecting numpy<=1.23\n",
      "  Using cached numpy-1.23.0-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting onnxruntime==1.13.1\n",
      "  Using cached onnxruntime-1.13.1-cp310-cp310-win_amd64.whl (5.9 MB)\n",
      "Requirement already satisfied: packaging>=20.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (23.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (3.8.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.38.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (0.42.0)\n",
      "Requirement already satisfied: pillow!=8.3,>=5.3.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from super-gradients) (10.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from onnx==1.13.0->super-gradients) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from onnxruntime==1.13.1->super-gradients) (1.12)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from onnxruntime==1.13.1->super-gradients) (23.5.26)\n",
      "Collecting coloredlogs\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting pyDeprecate==0.3.*\n",
      "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: future in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from treelib==1.6.1->super-gradients) (0.18.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from boto3>=1.17.15->super-gradients) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from boto3>=1.17.15->super-gradients) (0.7.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.84 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from boto3>=1.17.15->super-gradients) (1.31.84)\n",
      "Requirement already satisfied: platformdirs>=2.5.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from data-gradients~=0.3.1->super-gradients) (4.0.0)\n",
      "Collecting xhtml2pdf==0.2.11\n",
      "  Using cached xhtml2pdf-0.2.11-py3-none-any.whl\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from data-gradients~=0.3.1->super-gradients) (3.1.2)\n",
      "Collecting imagededup\n",
      "  Using cached imagededup-0.3.2-cp310-cp310-win_amd64.whl (53 kB)\n",
      "Collecting python-bidi>=0.4.2\n",
      "  Using cached python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
      "Collecting pypdf>=3.1.0\n",
      "  Using cached pypdf-3.17.1-py3-none-any.whl (277 kB)\n",
      "Collecting svglib>=1.2.1\n",
      "  Using cached svglib-1.5.1-py3-none-any.whl\n",
      "Collecting reportlab<4,>=3.5.53\n",
      "  Using cached reportlab-3.6.13-cp310-cp310-win_amd64.whl (2.3 MB)\n",
      "Collecting pyhanko-certvalidator>=0.19.5\n",
      "  Using cached pyhanko_certvalidator-0.26.2-py3-none-any.whl (109 kB)\n",
      "Collecting arabic-reshaper>=3.0.0\n",
      "  Using cached arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting html5lib>=1.0.1\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Collecting pyHanko>=0.12.1\n",
      "  Using cached pyHanko-0.21.0-py3-none-any.whl (433 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from Deprecated>=1.2.11->super-gradients) (1.14.1)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting referencing>=0.28.4\n",
      "  Using cached referencing-0.31.1-py3-none-any.whl (25 kB)\n",
      "Collecting rpds-py>=0.7.1\n",
      "  Using cached rpds_py-0.13.2-cp310-none-win_amd64.whl (188 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from jsonschema>=3.2.0->super-gradients) (23.1.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6\n",
      "  Using cached jsonschema_specifications-2023.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib>=3.3.4->super-gradients) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib>=3.3.4->super-gradients) (4.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib>=3.3.4->super-gradients) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib>=3.3.4->super-gradients) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from matplotlib>=3.3.4->super-gradients) (0.12.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from omegaconf->super-gradients) (6.0.1)\n",
      "Collecting rich\n",
      "  Using cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "Requirement already satisfied: tomli in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pip-tools>=6.12.1->super-gradients) (2.0.1)\n",
      "Collecting pip>=22.2\n",
      "  Using cached pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting click>=8\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting build\n",
      "  Using cached build-1.0.3-py3-none-any.whl (18 kB)\n",
      "Collecting alabaster<0.8,>=0.7\n",
      "  Using cached alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
      "Collecting sphinxcontrib-htmlhelp\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.4-py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from sphinx~=4.0.2->super-gradients) (0.4.6)\n",
      "Collecting sphinxcontrib-serializinghtml\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.9-py3-none-any.whl (92 kB)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting babel>=1.3\n",
      "  Using cached Babel-2.13.1-py3-none-any.whl (10.1 MB)\n",
      "Collecting snowballstemmer>=1.1\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting docutils<0.18,>=0.14\n",
      "  Using cached docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Using cached sphinxcontrib_devhelp-1.0.5-py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from sphinx~=4.0.2->super-gradients) (2.31.0)\n",
      "Collecting imagesize\n",
      "  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Using cached sphinxcontrib_qthelp-1.0.6-py3-none-any.whl (89 kB)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Using cached sphinxcontrib_applehelp-1.0.7-py3-none-any.whl (120 kB)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (1.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (2.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (0.7.2)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tensorboard>=2.4.1->super-gradients) (2.23.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch>=1.9.0->super-gradients) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch>=1.9.0->super-gradients) (2023.10.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch>=1.9.0->super-gradients) (3.2.1)\n",
      "Collecting sphinxcontrib-jquery<5,>=4\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Using cached sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from botocore<1.32.0,>=1.31.84->boto3>=1.17.15->super-gradients) (2.0.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->super-gradients) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from jinja2->data-gradients~=0.3.1->super-gradients) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.3.2)\n",
      "Collecting pyproject_hooks\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting PyWavelets\n",
      "  Using cached pywavelets-1.5.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from imagededup->data-gradients~=0.3.1->super-gradients) (1.1.3)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from seaborn->data-gradients~=0.3.1->super-gradients) (2.1.3)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Using cached sphinxcontrib_applehelp-1.0.6-py3-none-any.whl (120 kB)\n",
      "  Using cached sphinxcontrib_applehelp-1.0.5-py3-none-any.whl (120 kB)\n",
      "  Using cached sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Using cached sphinxcontrib_devhelp-1.0.4-py3-none-any.whl (83 kB)\n",
      "  Using cached sphinxcontrib_devhelp-1.0.3-py3-none-any.whl (83 kB)\n",
      "  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "Collecting sphinxcontrib-htmlhelp\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl (99 kB)\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl (99 kB)\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Using cached sphinxcontrib_qthelp-1.0.5-py3-none-any.whl (89 kB)\n",
      "  Using cached sphinxcontrib_qthelp-1.0.4-py3-none-any.whl (89 kB)\n",
      "  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "Collecting sphinxcontrib-serializinghtml\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl (92 kB)\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl (92 kB)\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl (92 kB)\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from sympy->onnxruntime==1.13.1->super-gradients) (1.3.0)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pandas>=1.2->seaborn->data-gradients~=0.3.1->super-gradients) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pandas>=1.2->seaborn->data-gradients~=0.3.1->super-gradients) (2023.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (0.5.1)\n",
      "Collecting cryptography>=41.0.5\n",
      "  Using cached cryptography-41.0.7-cp37-abi3-win_amd64.whl (2.7 MB)\n",
      "Collecting asn1crypto>=1.5.1\n",
      "  Using cached asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: tzlocal>=4.3 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients~=0.3.1->super-gradients) (5.2)\n",
      "Collecting qrcode>=7.3.1\n",
      "  Using cached qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
      "Collecting oscrypto>=1.1.0\n",
      "  Using cached oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
      "Collecting uritools>=3.0.1\n",
      "  Using cached uritools-4.0.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->super-gradients) (3.2.2)\n",
      "Collecting cssselect2>=0.2.0\n",
      "  Using cached cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
      "Collecting tinycss2>=0.6.0\n",
      "  Using cached tinycss2-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-4.9.3-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-learn->imagededup->data-gradients~=0.3.1->super-gradients) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-learn->imagededup->data-gradients~=0.3.1->super-gradients) (1.3.2)\n",
      "Collecting cffi>=1.12\n",
      "  Using cached cffi-1.16.0-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Collecting pypng\n",
      "  Using cached pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'error'\n",
      "Failed to build pycocotools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for pycocotools (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [17 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-310\n",
      "  creating build\\lib.win-amd64-cpython-310\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-cpython-310\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-cpython-310\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-cpython-310\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-cpython-310\\pycocotools\n",
      "  running build_ext\n",
      "  C:\\Users\\anssi\\AppData\\Local\\Temp\\pip-build-env-va9wcf4x\\overlay\\Lib\\site-packages\\Cython\\Compiler\\Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: C:\\Users\\anssi\\AppData\\Local\\Temp\\pip-install-vvnbxjrj\\pycocotools_2681990a7d4d4535b020f4ab84531ad0\\pycocotools\\_mask.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  Compiling pycocotools/_mask.pyx because it changed.\n",
      "  [1/1] Cythonizing pycocotools/_mask.pyx\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "ERROR: Could not build wheels for pycocotools, which is required to install pyproject.toml-based projects\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\anssi\\Desktop\\ai\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install fiftyone\n",
    "!pip install transformers\n",
    "!pip install super-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb0a0a6-2415-4477-9c5d-1039371aabe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\anssi\\Desktop\\ai\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02872f1-7ffa-4b42-9fa8-d6c802a49959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anssi\\Desktop\\ai\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anssi\\Desktop\\ai\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Model ready\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "# Run the model on GPU if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load a pre-trained Faster R-CNN model\n",
    "#model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7bd09d-81ab-449a-a1fe-2423b34e3cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0% |/--------------|    1/5000 [1.8ms elapsed, 8.9s remaining, 39.4K samples/s]     \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'000000000139.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m dataset_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./coco_adv_patch/validation/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m dataset_type \u001b[38;5;241m=\u001b[39m fo\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mCOCODetectionDataset\n\u001b[1;32m---> 12\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpersistent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     14\u001b[0m predictions_view \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m20\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m51\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\core\\dataset.py:5354\u001b[0m, in \u001b[0;36mDataset.from_dir\u001b[1;34m(cls, dataset_dir, dataset_type, data_path, labels_path, name, persistent, overwrite, label_field, tags, dynamic, **kwargs)\u001b[0m\n\u001b[0;32m   5260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a :class:`Dataset` from the contents of the given directory.\u001b[39;00m\n\u001b[0;32m   5261\u001b[0m \n\u001b[0;32m   5262\u001b[0m \u001b[38;5;124;03mYou can create datasets with this method via the following basic\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5351\u001b[0m \u001b[38;5;124;03m    a :class:`Dataset`\u001b[39;00m\n\u001b[0;32m   5352\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5353\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(name, persistent\u001b[38;5;241m=\u001b[39mpersistent, overwrite\u001b[38;5;241m=\u001b[39moverwrite)\n\u001b[1;32m-> 5354\u001b[0m dataset\u001b[38;5;241m.\u001b[39madd_dir(\n\u001b[0;32m   5355\u001b[0m     dataset_dir\u001b[38;5;241m=\u001b[39mdataset_dir,\n\u001b[0;32m   5356\u001b[0m     dataset_type\u001b[38;5;241m=\u001b[39mdataset_type,\n\u001b[0;32m   5357\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mdata_path,\n\u001b[0;32m   5358\u001b[0m     labels_path\u001b[38;5;241m=\u001b[39mlabels_path,\n\u001b[0;32m   5359\u001b[0m     label_field\u001b[38;5;241m=\u001b[39mlabel_field,\n\u001b[0;32m   5360\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[0;32m   5361\u001b[0m     dynamic\u001b[38;5;241m=\u001b[39mdynamic,\n\u001b[0;32m   5362\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   5363\u001b[0m )\n\u001b[0;32m   5364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\core\\dataset.py:4064\u001b[0m, in \u001b[0;36mDataset.add_dir\u001b[1;34m(self, dataset_dir, dataset_type, data_path, labels_path, label_field, tags, expand_schema, dynamic, add_info, **kwargs)\u001b[0m\n\u001b[0;32m   3962\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Adds the contents of the given directory to the dataset.\u001b[39;00m\n\u001b[0;32m   3963\u001b[0m \n\u001b[0;32m   3964\u001b[0m \u001b[38;5;124;03mYou can perform imports with this method via the following basic\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4053\u001b[0m \u001b[38;5;124;03m    a list of IDs of the samples that were added to the dataset\u001b[39;00m\n\u001b[0;32m   4054\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4055\u001b[0m dataset_importer, _ \u001b[38;5;241m=\u001b[39m foud\u001b[38;5;241m.\u001b[39mbuild_dataset_importer(\n\u001b[0;32m   4056\u001b[0m     dataset_type,\n\u001b[0;32m   4057\u001b[0m     dataset_dir\u001b[38;5;241m=\u001b[39mdataset_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4061\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4062\u001b[0m )\n\u001b[1;32m-> 4064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_importer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_importer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4070\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\core\\dataset.py:4640\u001b[0m, in \u001b[0;36mDataset.add_importer\u001b[1;34m(self, dataset_importer, label_field, tags, expand_schema, dynamic, add_info)\u001b[0m\n\u001b[0;32m   4595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_importer\u001b[39m(\n\u001b[0;32m   4596\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4597\u001b[0m     dataset_importer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4602\u001b[0m     add_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4603\u001b[0m ):\n\u001b[0;32m   4604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Adds the samples from the given\u001b[39;00m\n\u001b[0;32m   4605\u001b[0m \u001b[38;5;124;03m    :class:`fiftyone.utils.data.importers.DatasetImporter` to the dataset.\u001b[39;00m\n\u001b[0;32m   4606\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;124;03m        a list of IDs of the samples that were added to the dataset\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfoud\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset_importer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_field\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4647\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4648\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\utils\\data\\importers.py:143\u001b[0m, in \u001b[0;36mimport_samples\u001b[1;34m(dataset, dataset_importer, label_field, tags, expand_schema, dynamic, add_info)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(parse_sample, \u001b[38;5;28miter\u001b[39m(dataset_importer))\n\u001b[1;32m--> 143\u001b[0m sample_ids \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_info \u001b[38;5;129;01mand\u001b[39;00m dataset_importer\u001b[38;5;241m.\u001b[39mhas_dataset_info:\n\u001b[0;32m    151\u001b[0m     info \u001b[38;5;241m=\u001b[39m dataset_importer\u001b[38;5;241m.\u001b[39mget_dataset_info()\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\core\\dataset.py:2483\u001b[0m, in \u001b[0;36mDataset.add_samples\u001b[1;34m(self, samples, expand_schema, dynamic, validate, num_samples)\u001b[0m\n\u001b[0;32m   2481\u001b[0m sample_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m batcher:\n\u001b[1;32m-> 2483\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m batcher:\n\u001b[0;32m   2484\u001b[0m         _ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_samples_batch(\n\u001b[0;32m   2485\u001b[0m             batch, expand_schema, dynamic, validate\n\u001b[0;32m   2486\u001b[0m         )\n\u001b[0;32m   2487\u001b[0m         sample_ids\u001b[38;5;241m.\u001b[39mextend(_ids)\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\core\\utils.py:1104\u001b[0m, in \u001b[0;36mDynamicBatcher.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m batch_size:\n\u001b[1;32m-> 1104\u001b[0m         batch\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1105\u001b[0m         idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Desktop\\ai\\env\\lib\\site-packages\\fiftyone\\utils\\coco.py:433\u001b[0m, in \u001b[0;36mCOCODetectionDatasetImporter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    431\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 433\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image_paths_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    435\u001b[0m image_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image_dicts_map\u001b[38;5;241m.\u001b[39mget(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: '000000000139.jpg'"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "#dataset = foz.load_zoo_dataset(\n",
    " #   \"coco-2017\",\n",
    "  #  split=\"validation\",\n",
    "   # dataset_name=\"evaluate-detections-tutorial\",\n",
    "#)\n",
    "name=\"coco-patched-12345\"\n",
    "dataset_dir=\"./coco_adv_patch/validation/\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset.persistent = False\n",
    "predictions_view = dataset.take(20, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cd162-1aa2-4866-a99e-a8f72d9b3776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information about the dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93f110-350a-4492-8415-0f2b3861f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a ground truth detection\n",
    "sample = dataset.first()\n",
    "#print(sample.detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96301f03-dc94-4634-a280-f332f60e36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3528aa-c4d3-4491-bb9b-f2bf367d5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random subset of 100 samples to add predictions to\n",
    "#predictions_view = dataset.take(100, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc09341-6fe9-4b3f-8f70-d837cdb8bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import functional as func\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "# Get class list\n",
    "classes = dataset.default_classes\n",
    "\n",
    "# Add predictions to samples\n",
    "for sample in predictions_view:\n",
    "    image = Image.open(sample.filepath)\n",
    "\n",
    "    # you can specify the revision tag if you don't want the timm dependency\n",
    "    image_as_tensor = func.to_tensor(image).to(device)\n",
    "\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    c, h, w = image_as_tensor.shape\n",
    "\n",
    "    # convert outputs (bounding boxes and class logits) to COCO API\n",
    "    # let's only keep detections with score > 0.9\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "    detections = []\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        #print(\n",
    "         #       f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "          #      f\"{round(score.item(), 3)} at location {box}\"\n",
    "        #)\n",
    "        x1, y1, x2, y2 = box\n",
    "        rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "        \n",
    "    #for label, score, box in zip(labels, scores, boxes):\n",
    "        # Convert to [top-left-x, top-left-y, width, height]\n",
    "        # in relative coordinates in [0, 1] x [0, 1]\n",
    "     #   x1, y1, x2, y2 = box\n",
    "      #  rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
    "\n",
    "        detections.append(\n",
    "            fo.Detection(\n",
    "                label=model.config.id2label[label.item()],\n",
    "                bounding_box=rel_box,\n",
    "                confidence=score.item()\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Save predictions to dataset\n",
    "    sample[\"detr\"] = fo.Detections(detections=detections)\n",
    "    sample.save()\n",
    "print(detections)\n",
    "print(box)\n",
    "print(score.item())\n",
    "print(\"Finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8047f94-7066-4082-b084-8fbacd072271",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce749a8-2e47-44d9-944e-fca3fb4f29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "# Only contains detections with confidence >= 0.75\n",
    "high_conf_view = predictions_view.filter_labels(\"detr\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9910df86-632b-43b4-91f1-21ccecffbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information about the view\n",
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92ff36-1bc7-44d6-9e05-8ce241b5f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.detr.detections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d5310-3ed5-4d33-8cbd-192e9ca145ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load high confidence view in the App\n",
    "session.view = high_conf_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62ec0fb-1046-4c8b-8bdf-1d4d5846a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b329d75-cfac-4a9e-9644-2a23e09d47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = predictions_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b34d4a-947c-428e-bc80-a08f198fc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `detr` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = high_conf_view.evaluate_detections(\n",
    "    \"detr\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"detr_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7486859d-c087-47ee-8696-0cdf7d1ed829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829e298-80fe-49f5-9b21-44970e0a9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25901ec5-4dc0-4d52-9bdc-3f3fc8fd11d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envname",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
