{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning import (\n",
    "    BadDetRegionalMisclassificationAttack,\n",
    "    BadDetGlobalMisclassificationAttack,\n",
    "    BadDetObjectGenerationAttack,\n",
    "    BadDetObjectDisappearanceAttack,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from art.attacks.poisoning.perturbations import insert_image\n",
    "from art.estimators.object_detection.pytorch_detection_transformer import PyTorchDetectionTransformer\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_name = f\"run_images_detrpoisonimages\"\n",
    "\n",
    "try:\n",
    "   os.makedirs(directory_name)\n",
    "except OSError as e:\n",
    "   if e:\n",
    "       pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and Utility Functions\n",
    "\n",
    "Some constants and utility functions that will be used in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "\n",
    "# Path to the COCO annotations file\n",
    "coco_annotation_file = './coco_resized/validation/labels.json'\n",
    "\n",
    "# Load COCO annotations\n",
    "coco = COCO(coco_annotation_file)\n",
    "\n",
    "# Get all categories\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "\n",
    "# Extract the class names\n",
    "class_names = [category['name'] for category in categories]\n",
    "\n",
    "# Print the class names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES_OG = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', \n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_plot(img, predictions=None, filename=None, coco_instance_category_names=None):\n",
    "    text_size =  2\n",
    "    text_th =  3\n",
    "    rect_th =  2\n",
    "\n",
    "    img = img.copy()\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Transforming boxes from (x, y, w, h) to (x0, y0, x1, y1)\n",
    "        boxes = predictions['boxes'].astype(int)\n",
    "        transformed_boxes = []\n",
    "        for box in boxes:\n",
    "            x0, y0 = box[0], box[1]\n",
    "            x1 = x0 + box[2]\n",
    "            y1 = y0 + box[3]\n",
    "            transformed_boxes.append([x0, y0, x1, y1])\n",
    "\n",
    "        labels = predictions['labels']\n",
    "\n",
    "        # Draw rectangles with the transformed coordinates\n",
    "        for box, label in zip(transformed_boxes, labels):\n",
    "            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), color=(0,  255,  0), thickness=rect_th)\n",
    "\n",
    "            # Use the predefined list to get the category name\n",
    "            if COCO_INSTANCE_CATEGORY_NAMES is not None:\n",
    "                print(f\"number: {label}\")\n",
    "                text = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "                print(f\" cat name {text}\")\n",
    "            else:\n",
    "                text = f\"Label {label}\"  # Fallback if category names are not provided\n",
    "                print(f\"fall back:{text} \")\n",
    "\n",
    "            # Draw the text\n",
    "            cv2.putText(img, text, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, text_size, (255,  0,  0), thickness=text_th)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, interpolation=\"nearest\")\n",
    "    plt.show()\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_image_with_boxes(img, boxes, pred_cls, title, save, filename):\n",
    "    text_size = 2\n",
    "    text_th = 2\n",
    "    rect_th = 2\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
    "                      color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img, pred_cls[i], (int(boxes[i][0][0]), int(boxes[i][0][1])), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                    (0, 255, 0), thickness=text_th)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    if save == True and filename != None:\n",
    "       print(filename)\n",
    "       print(\"image saved\")\n",
    "       plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NUMBER_CHANNELS = 3\n",
    "INPUT_SHAPE = (NUMBER_CHANNELS, 800, 800)\n",
    "INPUT_SHAPE = (800, 800, 3)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([INPUT_SHAPE[1], INPUT_SHAPE[2]], interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "detector = PyTorchDetectionTransformer(channels_first=False, preprocessing=(MEAN, STD), input_shape=INPUT_SHAPE, clip_values=(0,1))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(predictions_, conf_thresh):\n",
    "    # Get the predicted class\n",
    "    predictions_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(predictions_[\"labels\"])]\n",
    "    #  print(\"\\npredicted classes:\", predictions_class)\n",
    "    if len(predictions_class) < 1:\n",
    "        return [], [], []\n",
    "    # Get the predicted bounding boxes\n",
    "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
    "\n",
    "    # Get the predicted prediction score\n",
    "    predictions_score = list(predictions_[\"scores\"])\n",
    "    # print(\"predicted score:\", predictions_score)\n",
    "\n",
    "    # Get a list of index with score greater than threshold\n",
    "    threshold = conf_thresh\n",
    "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold]\n",
    "    if len(predictions_t) > 0:\n",
    "        predictions_t = predictions_t  # [-1] #indices where score over threshold\n",
    "    else:\n",
    "        # no predictions esxceeding threshold\n",
    "        return [], [], []\n",
    "    # predictions in score order\n",
    "    predictions_boxes = [predictions_boxes[i] for i in predictions_t]\n",
    "    predictions_class = [predictions_class[i] for i in predictions_t]\n",
    "    predictions_scores = [predictions_score[i] for i in predictions_t]\n",
    "    return predictions_class, predictions_boxes, predictions_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We will be using two sample images from the dataset used by Ultralytics to train YOLO. \n",
    "\n",
    "We can use either a 4-D numpy array of size `N x H x W x C` or a list of numpy arrays of different sizes. For this demo, we use the latter to avoid needing to resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"poison_131\"\n",
    "name2=\"detect_103\"\n",
    "dataset_dir=\"./coco_resized/validation\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset_2 = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name2)\n",
    "\n",
    "dataset.persistent = False\n",
    "dataset_2.persistent = True\n",
    "to_poison = dataset.take(10, seed=51)\n",
    "predict_images = dataset_2.take(10, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "image_sizes = []\n",
    "# Now, all images are of the same size and can be stacked into a NumPy array\n",
    "x = []\n",
    "poison_image_ids = []\n",
    "for sample in to_poison:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    #image_id = image_id.lstrip('0')\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "\n",
    "    im = Image.open(sample.filepath)\n",
    "    im = im.convert('RGB')\n",
    "    im = np.asarray(im).copy()\n",
    "    im = (im / 255).astype(np.float32)\n",
    "    #display(im)\n",
    "\n",
    "    image_sizes.append(im.size)\n",
    "    poison_image_ids.append(image_id)\n",
    "\n",
    "    if im.shape != (3, 800, 800):\n",
    "        pass\n",
    "        #print(\"size doesn't match\")\n",
    "        #print(im.shape)\n",
    "    x.append(im)\n",
    "x = np.array(x)\n",
    "print(poison_image_ids)\n",
    "image_ids = []\n",
    "\n",
    "predict = []\n",
    "for sample in predict_images:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    #image_id = image_id.lstrip('0')\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "    image_ids.append(image_id)\n",
    "    im = Image.open(sample.filepath)\n",
    "    im = im.convert('RGB')\n",
    "    #im = np.asarray(im).copy()\n",
    "    #im = (im / 255).astype(np.float32)\n",
    "    im = transform(im).numpy()\n",
    "    #display(im)\n",
    "\n",
    "    image_sizes.append(im.size)\n",
    "\n",
    "    if im.shape != (3, 800, 800):\n",
    "        pass\n",
    "        #print(\"size doesn't match\")\n",
    "        #print(im.shape)\n",
    "    predict.append(im)\n",
    "predict = np.array(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using pre-defined bounding boxes and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Initialize COCO API for the annotations\n",
    "coco = COCO('./coco_resized/validation/labels.json')\n",
    "\n",
    "# Dictionary to store bounding boxes for each image ID\n",
    "bboxes_dict = {}\n",
    "bboxes_catid_dict = {}\n",
    "\n",
    "# Load the categories to map category IDs to names\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "cat_name_id_map = {cat['id']: cat['name'] for cat in cats}\n",
    "cat_name_id_map[69] = \"microwave\"\n",
    "cat_name_id_map[68] = \"cell phone\"\n",
    "cat_name_id_map[12] = \"stop sign\"\n",
    "cat_name_id_map[26] = \"umbrella\"\n",
    "cat_name_id_map[29] = \"suitcase\"\n",
    "cat_name_id_map[45] = \"spoon\"\n",
    "cat_name_id_map[30] = \"frisbee\"\n",
    "cat_name_id_map[0] = \"person\"\n",
    "mapped_bboxes =  []\n",
    "# Assuming poison_image_ids is defined elsewhere in your code\n",
    "for image_id in poison_image_ids:\n",
    "    # Get annotation IDs for the image\n",
    "    image_id = image_id.lstrip(\"0\")   \n",
    "    annotation_ids = coco.getAnnIds(imgIds=int(image_id))\n",
    "    # Load annotations\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    # Extract bounding boxes and store them in the dictionary\n",
    "    bboxes_dict[image_id] = [ann['bbox'] for ann in annotations]\n",
    "    # Store original category IDs without mapping\n",
    "    bboxes_catid_dict[image_id] = [ann['category_id'] for ann in annotations]\n",
    "    # Iterate over the category IDs for the current image and get their names\n",
    "    category_names = []\n",
    "    print(f\"label list should be: {len(bboxes_dict[image_id])}\")\n",
    "    store_list = []\n",
    "    for category_id in bboxes_catid_dict[image_id]:\n",
    "        category = coco.loadCats(category_id)[0]\n",
    "        category_names.append(category['name'])\n",
    "        if category[\"name\"] in COCO_INSTANCE_CATEGORY_NAMES:\n",
    "            # Store the changed label id to the list...\n",
    "            if COCO_INSTANCE_CATEGORY_NAMES.index(category[\"name\"]) == 0:\n",
    "                store_list.append(1)\n",
    "            else:\n",
    "                store_list.append(COCO_INSTANCE_CATEGORY_NAMES.index(category[\"name\"]))\n",
    "            bboxes_catid_dict[image_id] = store_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = []\n",
    "\n",
    "\n",
    "\n",
    "for image_id, bboxes in bboxes_dict.items():\n",
    "    test_entry = {\n",
    "        'boxes': np.empty((0,  4), dtype=np.float32),\n",
    "        'labels': np.array(bboxes_catid_dict[image_id])\n",
    "    }\n",
    "    #print(image_id)\n",
    "\n",
    "    new_bboxes_np = np.asarray(bboxes, dtype=np.float32)\n",
    "    try:\n",
    "        test_entry['boxes'] = np.vstack((test_entry['boxes'], new_bboxes_np))\n",
    "        print(test_entry[\"labels\"])\n",
    "        #print(test_entry[\"boxes\"], len(test_entry[\"boxes\"]))\n",
    "        #print(test_entry[\"labels\"],len(test_entry[\"labels\"]))\n",
    "    except:\n",
    "        print(image_id)\n",
    "        #print(test_entry[\"boxes\"])\n",
    "        #print(test_entry[\"labels\"])\n",
    "        #print(image_id)\n",
    "        pass\n",
    "\n",
    "    y.append(test_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Backdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Trigger\n",
    "\n",
    "We will be using the HTBD backdoor trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_path = '/scratch/project_2008539/htbd.png'\n",
    "trigger = Image.open(trigger_path)\n",
    "trigger = np.asarray(trigger, dtype=np.float32)\n",
    "\n",
    "#test_plot(trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_func(x):\n",
    "    return insert_image(x, backdoor_path=trigger_path, size=(29, 29), mode='RGB', blend=0.8, random=False, x_shift=0, y_shift=0)\n",
    "backdoor = PoisoningAttackBackdoor(poison_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    test_plot(x[i], y[i], filename=f\"{directory_name}/clean{i+10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_i in x:\n",
    "    x_poisoned, _ = backdoor.poison(x_i[np.newaxis], [])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this backdoor object, we can perform the four BadDet poisoning attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Regional Misclassification Attack\n",
    "\n",
    "The BadNet Regional Misclassification Attack (RMA) will insert the trigger into the bounding box of the source class and change the classification label to the target class. We will use class 0 (person) as the source and class 1 (bicycle) as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack = BadDetRegionalMisclassificationAttack(backdoor, class_source=0, class_target=1, percent_poison=1.0)\n",
    "\n",
    "\n",
    "x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "for i in range(10):\n",
    "    test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_rma{i}\")\n",
    "    \n",
    "for i in range(10):\n",
    "    test_plot(x[i], y[i], filename=f\"{directory_name}/clean{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Global Misclassification Attack\n",
    "\n",
    "The BadNet Global Misclassification Attack (GMA) will insert the trigger onto the image and change all classification labels to the target class, regardless of the source class. We will use class 1 (bicycle) as the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack = BadDetGlobalMisclassificationAttack(backdoor, class_target=1, percent_poison=1.0)\n",
    "#x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "\n",
    "#for i in range(50):\n",
    "    #test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_gma{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Object Generation Attack\n",
    "\n",
    "The BadDet Object Generation Attack (OGA) will insert the trigger onto the image at a random location and create a fake bounding box and classification for that label. We will class 1 (bicycle) as the target class and use a bounding box of size 50 x 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack = BadDetObjectGenerationAttack(backdoor, bbox_height=200, bbox_width=150, class_target=1, percent_poison=1.0)\n",
    "#x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "#for i in range(50):\n",
    "#    test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_oga{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Object Disappearance Attack\n",
    "\n",
    "The BadDet Object Disappearance Attack (ODA) will insert the trigger into the bounding box of the source class and delete that bounding box and corresponding classification. We will poison class 0 (person) as the source class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attack = BadDetObjectDisappearanceAttack(backdoor, class_source=0, percent_poison=1.0)\n",
    "#x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "\n",
    "#for i in range(50):\n",
    " #   test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_oda{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ART Model\n",
    "\n",
    "For this demo, we will be using the Faster R-CNN classifier as this model accepts images of any dimension. To use the YOLO v3 or YOLO v5 estimators, you must resize all the images to `416 x 416`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate map before poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = detector.predict(predict)\n",
    "\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height  # ymax\n",
    "       ]\n",
    "\n",
    "\n",
    "        #Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "        # boksit normalisoitu 01 pitäs olla 0255\n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "       print(detections)\n",
    "    #plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions attacked images\")\n",
    "    #plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"\", save=True, filename=f\"{directory_name}/benign_model{i}\")\n",
    "\n",
    "    sample = dataset_2[f\"/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg\"]\n",
    "    sample[\"nopoison\"] = fo.Detections(detections=detections)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predict_images.filter_labels(\"nopoison\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.nopoison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predict_images.evaluate_detections(\n",
    "    \"nopoison\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"nopoison_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_before = results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detector.fit(x_poisoned, y_poisoned, nb_epochs=1)\n",
    "# älä viitti :D\n",
    "print(\"Model retrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly calculate map after poisoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = detector.predict(predict)\n",
    "\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height  # ymax\n",
    "       ]\n",
    "       # Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "    \n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       \n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "    #plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions attacked images\")\n",
    "    \n",
    "    plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"\", save=True, filename=f\"{directory_name}/after_poison{i}\")\n",
    "    sample = dataset_2[f\"/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg\"]\n",
    "    sample[\"afterpoison\"] = fo.Detections(detections=detections)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predict_images.filter_labels(\"afterpoison\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.afterpoison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predict_images.evaluate_detections(\n",
    "    \"afterpoison\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"afterpoison_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_after = results.mAP()\n",
    "print(result_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{name}.txt\", \"w\")\n",
    "print(f\"saved as: {file}\")\n",
    "#convert variable to string\n",
    "result_before = str(result_before)\n",
    "result_after = str(result_after)\n",
    "\n",
    "file.write(\"before poisoning: = \" + result_before + \"\\n\" + \"after poisoning\" + result_after + \"\\n\")\n",
    "\n",
    "#close file\n",
    "file.close()\n",
    "\n",
    "print(\"Success!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "30b15819a73bf738d2c051012d518af2175fe5da693b3ec4b95bab668851eb25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
