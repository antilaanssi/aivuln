{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define imports, constants and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.object_detection.pytorch_detection_transformer import PyTorchDetectionTransformer\n",
    "from art.attacks.evasion.adversarial_patch.adversarial_patch_pytorch import AdversarialPatchPyTorch\n",
    "from torchvision.transforms import transforms\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import fiftyone as fo\n",
    "\n",
    "COCO_CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "def extract_predictions(predictions_, conf_thresh):\n",
    "    predictions_class = [COCO_CLASSES[i] for i in list(predictions_[\"labels\"])]\n",
    "    if len(predictions_class) < 1:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
    "    predictions_score = list(predictions_[\"scores\"])\n",
    "\n",
    "    threshold = conf_thresh\n",
    "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold]\n",
    "    if len(predictions_t) > 0:\n",
    "        predictions_t = predictions_t\n",
    "    else:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [predictions_boxes[i] for i in predictions_t]\n",
    "    predictions_class = [predictions_class[i] for i in predictions_t]\n",
    "    predictions_scores = [predictions_score[i] for i in predictions_t]\n",
    "    return predictions_class, predictions_boxes, predictions_scores\n",
    "\n",
    "def plot_image_with_boxes(img, boxes, pred_cls, title, save, filename):\n",
    "    text_size = 2\n",
    "    text_th = 2\n",
    "    rect_th = 2\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
    "                      color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img, pred_cls[i], (int(boxes[i][0][0]), int(boxes[i][0][1])), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                    (0, 255, 0), thickness=text_th)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    if save == True and filename != None:\n",
    "       print(filename)\n",
    "       print(\"image saved\")\n",
    "       plt.savefig(filename)\n",
    "\n",
    "def filter_boxes(predictions, conf_thresh):\n",
    "    dictionary = {}\n",
    "\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for i in range(len(predictions[0][\"boxes\"])):\n",
    "        score = predictions[0][\"scores\"][i]\n",
    "        if score >= conf_thresh:\n",
    "            boxes_list.append(predictions[0][\"boxes\"][i])\n",
    "            scores_list.append(predictions[0][\"scores\"][[i]])\n",
    "            labels_list.append(predictions[0][\"labels\"][[i]])\n",
    "\n",
    "    dictionary[\"boxes\"] = np.vstack(boxes_list)\n",
    "    dictionary[\"scores\"] = np.hstack(scores_list)\n",
    "    dictionary[\"labels\"] = np.hstack(labels_list)\n",
    "\n",
    "    y = [dictionary]\n",
    "\n",
    "    return y\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NUMBER_CHANNELS = 3\n",
    "INPUT_SHAPE = (NUMBER_CHANNELS, 800, 800)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([INPUT_SHAPE[1], INPUT_SHAPE[2]], interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"yolo_patch_on_detr_transfer\"\n",
    "dataset_dir=\"./coco_resized/validation/\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset.persistent = False\n",
    "#predictions_view = dataset.take(2, seed=51)\n",
    "predictions_view = dataset.take(50, seed=51)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load COCO images and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "image_ids = []\n",
    "image_sizes = []\n",
    "unsized_images = []\n",
    "import PIL\n",
    "import os\n",
    "for sample in predictions_view:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "    image_ids.append(image_id)\n",
    "    \n",
    "    im = PIL.Image.open(sample.filepath)\n",
    "    \n",
    "    \n",
    "    im = im.convert('RGB')\n",
    "\n",
    "    image_sizes.append(im.size)\n",
    "    im = transform(im).numpy()\n",
    "    \n",
    "    coco_images.append(im)\n",
    "coco_images = np.array(coco_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = PyTorchDetectionTransformer(channels_first=True, preprocessing=(MEAN, STD), input_shape=INPUT_SHAPE, clip_values=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test detector on COCO images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_name = f\"run_images_{name}\"\n",
    "\n",
    "try:\n",
    "   os.makedirs(directory_name)\n",
    "except OSError as e:\n",
    "   if e.errno != errno.EEXIST:\n",
    "       raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = detector.predict(coco_images)\n",
    "for i in range(len(results)):\n",
    "    preds_orig = extract_predictions(results[i], 0.8)\n",
    "    im = (torch.from_numpy(coco_images)[i].numpy().transpose(1,2,0)*255).astype(np.uint8)\n",
    "    plot_image_with_boxes(img=coco_images[i].transpose(1,2,0).copy(), boxes=preds_orig[1], pred_cls=preds_orig[0], title=\"Predictions on image without patch\", save=True, filename=f\"{directory_name}/benign{i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dets = detector.predict(coco_images)\n",
    "y = [filter_boxes([t], 0.8)[0] for t in dets]\n",
    "\n",
    "x = coco_images[:-1]\n",
    "target = [y[-1] for i in range(len(coco_images[:-1]))]\n",
    "\n",
    "rotation_max=0.0\n",
    "scale_min=0.5\n",
    "scale_max=1\n",
    "distortion_scale_max=0.0\n",
    "learning_rate=1.99\n",
    "max_iter=1\n",
    "batch_size=16\n",
    "patch_shape=(3, 200, 200)\n",
    "patch_location=(400,400)\n",
    "patch_type=\"square\"\n",
    "optimizer=\"adam\"\n",
    "\n",
    "attack = AdversarialPatchPyTorch(estimator=detector, rotation_max=rotation_max, \n",
    "                      scale_min=scale_min, scale_max=scale_max, distortion_scale_max=distortion_scale_max,\n",
    "                      learning_rate=learning_rate, max_iter=max_iter, batch_size=batch_size, patch_location=patch_location,\n",
    "                      patch_shape=patch_shape, patch_type=patch_type, verbose=False, targeted=False)\n",
    "\n",
    "loss_history = []\n",
    "count = 0\n",
    "for i in tqdm(range(2)):\n",
    "    patch = attack.generate(x[[0]], y[:1])\n",
    "    patched_images = attack.apply_patch(x, scale=0.4) # 0.1\n",
    "\n",
    "_y = detector.predict(transfer)\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height  # ymax\n",
    "       ]\n",
    "       # Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "    \n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       \n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "    plot_image_with_boxes(img=patched_images[i].transpose(1,2,0).copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions on image with patch\", save=True, filename=f\"{directory_name}/patched{i}\")\n",
    "    sample = dataset[f\"/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg\"]\n",
    "    sample[\"detr\"] = fo.Detections(detections=detections)\n",
    "    sample.save()\n",
    "print(\"finished adding predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predictions_view.filter_labels(\"detr\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.detr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predictions_view.evaluate_detections(\n",
    "    \"detr\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"yolo_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{name}.txt\", \"w\")\n",
    "print(f\"saved as: {file}\")\n",
    "#convert variable to string\n",
    "result = str(result)\n",
    "file.write(\"result = \" + result + \"\\n\")\n",
    "\n",
    "#close file\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7655704a78de5a379a432c4d72390505dcf1b4e8d049e60ccc7e7a065a9da92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
