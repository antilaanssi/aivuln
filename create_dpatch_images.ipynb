{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeebc9f4-1e8d-46b0-b68f-12cda41c1516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from adversarial-robustness-toolbox) (1.26.2)\n",
      "Requirement already satisfied: six in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from adversarial-robustness-toolbox) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from adversarial-robustness-toolbox) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from adversarial-robustness-toolbox) (58.1.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from adversarial-robustness-toolbox) (1.11.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\anssi\\desktop\\ai\\env\\lib\\site-packages (from tqdm->adversarial-robustness-toolbox) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\anssi\\Desktop\\ai\\env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f59977-563a-4fd0-b241-7db8d1978daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anssi\\Desktop\\ai\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from art.estimators.object_detection.pytorch_detection_transformer import PyTorchDetectionTransformer\n",
    "from art.attacks.evasion.adversarial_patch.adversarial_patch_pytorch import AdversarialPatchPyTorch\n",
    "from torchvision.transforms import transforms\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d09e89-51bb-4a0f-a692-0608017736d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coco-123', 'coco-1234', 'coco-2017-validation-50', 'coco-800', 'coco-most_original', 'coco-original', 'coco-patched-1', 'coco-patched-1234', 'coco-patched-12345', 'coco-patched-test1', 'coco-patched-test12', 'coco-re', 'coco-res', 'coco-resized', 'coco-resized-to-800', 'coco-resized-to-800-2', 'coco-resizer', 'coco-to-dpatch', 'coco-to-dpatch-2', 'coco-to-dpatch-3', 'coco-to-dpatch-4', 'coco-to-dpatch-5', 'coco-to-dpatch-6', 'coco-to-resized_testing', 'coco-to-resized_testing-2', 'coco-to-resized_testing-3', 'coco-to-resized_testing-4', 'coco-to-resized_testing-5', 'coco_224', 'evaluate-detections-tutorial', 'patched', 'patched-1', 'patched-2', 'patched-3', 'patched-31233445365', 'patched-312334453655', 'patched-3123345', 'patched-321', 'resize', 'test']\n",
      " 100% |███████████████| 5000/5000 [18.7s elapsed, 0s remaining, 274.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "print(fo.list_datasets())\n",
    "\n",
    "#dataset = foz.load_zoo_dataset(\n",
    " #   \"coco-resized-to-800\",\n",
    "  #  split=\"validation\",\n",
    "   # dataset_name=\"dpatched-images\",\n",
    "#)\n",
    "\n",
    "name=\"patched-321212121\"\n",
    "dataset_dir=\"./coco_resized/validation\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset.persistent = False\n",
    "predictions_view = dataset.take(5000, seed=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03fecb1a-f5b1-497f-8a2a-598aa7a3a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f454e1f-ffe1-49ec-a725-8de1964dacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_boxes(predictions, conf_thresh):\n",
    "    dictionary = {}\n",
    "\n",
    "    boxes_list = []\n",
    "    scores_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for i in range(len(predictions[0][\"boxes\"])):\n",
    "        score = predictions[0][\"scores\"][i]\n",
    "        if score >= conf_thresh:\n",
    "            boxes_list.append(predictions[0][\"boxes\"][i])\n",
    "            scores_list.append(predictions[0][\"scores\"][[i]])\n",
    "            labels_list.append(predictions[0][\"labels\"][[i]])\n",
    "\n",
    "    dictionary[\"boxes\"] = np.vstack(boxes_list)\n",
    "    dictionary[\"scores\"] = np.hstack(scores_list)\n",
    "    dictionary[\"labels\"] = np.hstack(labels_list)\n",
    "\n",
    "    y = [dictionary]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa39c18-fca3-405e-8f93-c20224e32329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(img, boxes, pred_cls, title):\n",
    "    text_size = 2\n",
    "    text_th = 2\n",
    "    rect_th = 2\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
    "                      color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img, pred_cls[i], (int(boxes[i][0][0]), int(boxes[i][0][1])), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                    (0, 255, 0), thickness=text_th)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb2bfac-2ac6-4599-ae4f-60ad6f47dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(predictions_, conf_thresh):\n",
    "    predictions_class = [COCO_CLASSES[i] for i in list(predictions_[\"labels\"])]\n",
    "    if len(predictions_class) < 1:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
    "    predictions_score = list(predictions_[\"scores\"])\n",
    "\n",
    "    threshold = conf_thresh\n",
    "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold]\n",
    "    if len(predictions_t) > 0:\n",
    "        predictions_t = predictions_t\n",
    "    else:\n",
    "        return [], [], []\n",
    "        \n",
    "    predictions_boxes = [predictions_boxes[i] for i in predictions_t]\n",
    "    predictions_class = [predictions_class[i] for i in predictions_t]\n",
    "    predictions_scores = [predictions_score[i] for i in predictions_t]\n",
    "    return predictions_class, predictions_boxes, predictions_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9c6344-bcb4-4698-862f-03d422156a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "NUMBER_CHANNELS = 3\n",
    "INPUT_SHAPE = (NUMBER_CHANNELS, 800, 800)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([INPUT_SHAPE[1], INPUT_SHAPE[2]], interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59b2095-adfd-4263-86e1-698e72a9cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\anssi/.cache\\torch\\hub\\facebookresearch_detr_main\n",
      "C:\\Users\\anssi\\Desktop\\ai\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anssi\\Desktop\\ai\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "detector = PyTorchDetectionTransformer(channels_first=True, preprocessing=(MEAN, STD), input_shape=INPUT_SHAPE, clip_values=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40241343-c417-49d8-bc9f-df19ccc95897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers(filename):\n",
    "   numbers = re.findall(r'\\d+', filename)\n",
    "   return ''.join(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba09d23-24f5-4da6-a101-af84df282627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f8a2fd5-6f3e-4965-83d4-246961d85f55",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 35.8 GiB for an array with shape (5000, 3, 800, 800) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(im\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     22\u001b[0m     coco_images\u001b[38;5;241m.\u001b[39mappend(im)\n\u001b[1;32m---> 23\u001b[0m coco_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoco_images\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 35.8 GiB for an array with shape (5000, 3, 800, 800) and data type float32"
     ]
    }
   ],
   "source": [
    "import os\n",
    "coco_images = []\n",
    "image_ids = []\n",
    "image_sizes = []\n",
    "unsized_images = []\n",
    "for sample in predictions_view:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    image_id = image_id.lstrip('0')\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "    image_ids.append(image_id)\n",
    "    im = PIL.Image.open(sample.filepath)\n",
    "    im = im.convert('RGB')\n",
    "    image_sizes.append(im.size)\n",
    "    #print(im.dtype) # Print the data type of the image\n",
    "    #print(f\"shape before: {im.shape}\")\n",
    "    im = transform(im).numpy()\n",
    "    #print(f\"shape after: {im.shape}\")\n",
    "    if im.shape != (3, 800, 800):\n",
    "        print(\"size doesn't match\")\n",
    "        print(im.shape)\n",
    "\n",
    "    coco_images.append(im)\n",
    "coco_images = np.array(coco_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffc21b-2be2-46f9-8be5-801a49d16d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pullaa nämä fiftyonesta:\n",
    "dets = detector.predict(coco_images[:20]) # ttämä pakko rajottaa ja keksiä joku syy dippaan sille...\n",
    "filtered_dets = [filter_boxes([t], 0.8)[0] for t in dets]\n",
    "\n",
    "x = coco_images[:-1]\n",
    "targets = [filtered_dets[-1] for i in range(len(x))]\n",
    "\n",
    "rotation_max=0.0\n",
    "scale_min=0.5\n",
    "scale_max=1\n",
    "distortion_scale_max=0.0\n",
    "learning_rate=1.99\n",
    "max_iter=400\n",
    "batch_size=16\n",
    "patch_shape=(3, 200, 200)\n",
    "patch_location=(100,100)\n",
    "patch_type=\"square\"\n",
    "optimizer=\"adam\"\n",
    "\n",
    "ap = AdversarialPatchPyTorch(estimator=detector, rotation_max=rotation_max, \n",
    "                      scale_min=scale_min, scale_max=scale_max, distortion_scale_max=distortion_scale_max,\n",
    "                      learning_rate=learning_rate, max_iter=max_iter, batch_size=batch_size, patch_location=patch_location,\n",
    "                      patch_shape=patch_shape, patch_type=patch_type, verbose=True, targeted=False)\n",
    "\n",
    "patch, patch_mask = ap.generate(x=x[[0]], y=filtered_dets[:1])\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(((patch) * patch_mask).transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e28987-2f85-40ca-915b-f9ed16203f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÄHÄN NYT TUON COCO_IMAGESIN TILALLE FIFTYONESTA NE KUVAT\n",
    "# Nyt kun saadaan fiftyonesta kuvat\n",
    "# pitää tallentaa nämä patchatyt kuvat levylle jonnekin...\n",
    "import cv2\n",
    "import imageio\n",
    "#for image in coco_images:\n",
    "length = len(coco_images)\n",
    "patched_images = ap.apply_patch(coco_images[:length], scale=0.4)\n",
    "i=0\n",
    "for image in patched_images:\n",
    "    #print(image)\n",
    "    image = (image * 255).astype('uint8')\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    img = PIL.Image.fromarray(image)\n",
    "    img.save(f'E:\\\\coco_patched\\\\data\\\\{image_ids[i]}.jpg')\n",
    "    print(\"image saved\")\n",
    "    # this still needs to be resized into the original output and needs the correct id attached...\n",
    "    i+=1\n",
    "#dets = detector.predict(patched_images)\n",
    "#for i in range(len(dets)):\n",
    " #   preds_orig = extract_predictions(dets[i], 0.8)\n",
    "  #  plot_image_with_boxes(img=patched_images[i].transpose(1,2,0).copy(), boxes=preds_orig[1], pred_cls=preds_orig[0],\n",
    "   #                        title=\"Predictions on image with patch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d796bf-fba9-4820-90d2-a55dbf608c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envname",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
