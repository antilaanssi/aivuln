{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning import (\n",
    "    BadDetRegionalMisclassificationAttack,\n",
    "    BadDetGlobalMisclassificationAttack,\n",
    "    BadDetObjectGenerationAttack,\n",
    "    BadDetObjectDisappearanceAttack,\n",
    ")\n",
    "\n",
    "from torchvision.transforms import transforms\n",
    "from art.attacks.poisoning.perturbations import insert_image\n",
    "from art.estimators.object_detection import PyTorchFasterRCNN, PyTorchYolo\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory_name = f\"run_images_testplotimages\"\n",
    "\n",
    "try:\n",
    "   os.makedirs(directory_name)\n",
    "except OSError as e:\n",
    "   if e:\n",
    "       pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "\n",
    "# Path to the COCO annotations file\n",
    "coco_annotation_file = './coco_resized/validation/labels.json'\n",
    "\n",
    "# Load COCO annotations\n",
    "coco = COCO(coco_annotation_file)\n",
    "\n",
    "# Get all categories\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "\n",
    "# Extract the class names\n",
    "class_names = [category['name'] for category in categories]\n",
    "\n",
    "# Print the class names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', \n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', \n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def test_plot(img, predictions=None, filename=None, coco_instance_category_names=None):\n",
    "    text_size =  2\n",
    "    text_th =  3\n",
    "    rect_th =  2\n",
    "\n",
    "    img = img.copy()\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Transforming boxes from (x, y, w, h) to (x0, y0, x1, y1)\n",
    "        boxes = predictions['boxes'].astype(int)\n",
    "        transformed_boxes = []\n",
    "        for box in boxes:\n",
    "            x0, y0 = box[0], box[1]\n",
    "            x1 = x0 + box[2]\n",
    "            y1 = y0 + box[3]\n",
    "            transformed_boxes.append([x0, y0, x1, y1])\n",
    "\n",
    "        labels = predictions['labels']\n",
    "\n",
    "        # Draw rectangles with the transformed coordinates\n",
    "        for box, label in zip(transformed_boxes, labels):\n",
    "            cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), color=(0,  255,  0), thickness=rect_th)\n",
    "            # Use the predefined list to get the category name\n",
    "            if COCO_INSTANCE_CATEGORY_NAMES is not None:\n",
    "                print(f\"number: {label}\")\n",
    "                text = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "                #if text == \"bicycle\":\n",
    "                #    text = \"person\"\n",
    "                print(f\" cat name {text}\")\n",
    "            else:\n",
    "                text = f\"Label {label}\"  # Fallback if category names are not provided\n",
    "               # if text == \"bicycle\":\n",
    "                #    text = \"person\"\n",
    "                #print(f\"fall back:{text} \")\n",
    "\n",
    "            # Draw the text\n",
    "            cv2.putText(img, text, (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, text_size, (255,  0,  0), thickness=text_th)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img, interpolation=\"nearest\")\n",
    "    plt.show()\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_image_with_boxes(img, boxes, pred_cls, title, save, filename):\n",
    "    text_size = 2\n",
    "    text_th = 2\n",
    "    rect_th = 2\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, (int(boxes[i][0][0]), int(boxes[i][0][1])), (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
    "                      color=(0, 255, 0), thickness=rect_th)\n",
    "        cv2.putText(img, pred_cls[i], (int(boxes[i][0][0]), int(boxes[i][0][1])), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                    (0, 255, 0), thickness=text_th)\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    if save == True and filename != None:\n",
    "       print(filename)\n",
    "       print(\"image saved\")\n",
    "       plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yolov5\n",
    "from yolov5.utils.loss import ComputeLoss\n",
    "\n",
    "\n",
    "def load_yolo_v5():\n",
    "    class Yolo(torch.nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.model.hyp = {\n",
    "                'box': 0.05,\n",
    "                'obj': 1.0,\n",
    "                'cls': 0.5,\n",
    "                'anchor_t': 4.0,\n",
    "                'cls_pw': 1.0,\n",
    "                'obj_pw': 1.0,\n",
    "                'fl_gamma': 0.0,\n",
    "            }\n",
    "            self.compute_loss = ComputeLoss(self.model.model.model)\n",
    "\n",
    "        def forward(self, x, targets=None):\n",
    "            if self.training:\n",
    "                outputs = self.model.model.model(x)\n",
    "                loss, _ = self.compute_loss(outputs, targets)\n",
    "                loss_components_dict = {\"loss_total\": loss}\n",
    "                return loss_components_dict\n",
    "            else:\n",
    "                return self.model(x)\n",
    "\n",
    "    model = yolov5.load('yolov5s.pt')\n",
    "    model_wrapper = Yolo(model)\n",
    "\n",
    "    for k, v in model_wrapper.named_parameters():\n",
    "        v.requires_grad = True  # train all layers\n",
    "\n",
    "    params = [p for p in model_wrapper.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.01)\n",
    "\n",
    "    detector = PyTorchYolo(\n",
    "        model=model_wrapper,\n",
    "        device_type='gpu',\n",
    "        input_shape=(800, 800, 3),\n",
    "        optimizer=optimizer,\n",
    "        clip_values=(0, 1),\n",
    "        channels_first=False,\n",
    "        attack_losses=(\"loss_total\",)\n",
    "    )\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = load_yolo_v5()\n",
    "\n",
    "test_detector = load_yolo_v5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_predictions(predictions_, conf_thresh):\n",
    "    # Get the predicted class\n",
    "    predictions_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(predictions_[\"labels\"])]\n",
    "    #  print(\"\\npredicted classes:\", predictions_class)\n",
    "    if len(predictions_class) < 1:\n",
    "        return [], [], []\n",
    "    # Get the predicted bounding boxes\n",
    "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
    "\n",
    "    # Get the predicted prediction score\n",
    "    predictions_score = list(predictions_[\"scores\"])\n",
    "    # print(\"predicted score:\", predictions_score)\n",
    "\n",
    "    # Get a list of index with score greater than threshold\n",
    "    threshold = conf_thresh\n",
    "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold]\n",
    "    if len(predictions_t) > 0:\n",
    "        predictions_t = predictions_t  # [-1] #indices where score over threshold\n",
    "    else:\n",
    "        # no predictions esxceeding threshold\n",
    "        return [], [], []\n",
    "    # predictions in score order\n",
    "    predictions_boxes = [predictions_boxes[i] for i in predictions_t]\n",
    "    predictions_class = [predictions_class[i] for i in predictions_t]\n",
    "    predictions_scores = [predictions_score[i] for i in predictions_t]\n",
    "    return predictions_class, predictions_boxes, predictions_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"poison_244\"\n",
    "name2=\"detect_239\"\n",
    "dataset_dir=\"./coco_resized/validation\"\n",
    "dataset_type = fo.types.COCODetectionDataset\n",
    "dataset = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name)\n",
    "dataset_2 = fo.Dataset.from_dir(dataset_dir, dataset_type, name=name2)\n",
    "\n",
    "dataset.persistent = False # change when doing the actual test\n",
    "dataset_2.persistent = True\n",
    "to_poison = dataset.take(120, seed=51) # 51\n",
    "predict_images = dataset_2.take(50, seed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "image_sizes = []\n",
    "# Now, all images are of the same size and can be stacked into a NumPy array\n",
    "x = []\n",
    "poison_image_ids = []\n",
    "for sample in to_poison:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    #image_id = image_id.lstrip('0')\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "\n",
    "    im = Image.open(sample.filepath)\n",
    "    im = im.convert('RGB')\n",
    "    im = np.asarray(im).copy()\n",
    "    im = (im / 255).astype(np.float32)\n",
    "    #display(im)\n",
    "\n",
    "    image_sizes.append(im.size)\n",
    "    poison_image_ids.append(image_id)\n",
    "\n",
    "    if im.shape != (3, 800, 800):\n",
    "        pass\n",
    "        #print(\"size doesn't match\")\n",
    "        #print(im.shape)\n",
    "    x.append(im)\n",
    "x = np.array(x)\n",
    "image_ids = []\n",
    "\n",
    "predict = []\n",
    "for sample in predict_images:\n",
    "    image_id = os.path.basename(sample.filepath)\n",
    "    #image_id = image_id.lstrip('0')\n",
    "    image_id = image_id.replace('.jpg', '')\n",
    "    image_ids.append(image_id)\n",
    "    im = Image.open(sample.filepath)\n",
    "    im = im.convert('RGB')\n",
    "    im = np.asarray(im).copy()\n",
    "    im = (im / 255).astype(np.float32)\n",
    "    #display(im)\n",
    "\n",
    "    image_sizes.append(im.size)\n",
    "\n",
    "    if im.shape != (3, 800, 800):\n",
    "        pass\n",
    "        #print(\"size doesn't match\")\n",
    "        #print(im.shape)\n",
    "    predict.append(im)\n",
    "predict = np.array(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Initialize COCO API for the annotations\n",
    "coco = COCO('./coco_resized/validation/labels.json')\n",
    "\n",
    "# Dictionary to store bounding boxes for each image ID\n",
    "bboxes_dict = {}\n",
    "bboxes_catid_dict = {}\n",
    "\n",
    "# Load the categories to map category IDs to names\n",
    "cats = coco.loadCats(coco.getCatIds())\n",
    "cat_name_id_map = {cat['id']: cat['name'] for cat in cats}\n",
    "cat_name_id_map[69] = \"microwave\"\n",
    "cat_name_id_map[68] = \"cell phone\"\n",
    "cat_name_id_map[12] = \"stop sign\"\n",
    "cat_name_id_map[26] = \"umbrella\"\n",
    "cat_name_id_map[29] = \"suitcase\"\n",
    "cat_name_id_map[45] = \"spoon\"\n",
    "cat_name_id_map[30] = \"frisbee\"\n",
    "cat_name_id_map[0] = \"person\"\n",
    "mapped_bboxes =  []\n",
    "# Assuming poison_image_ids is defined elsewhere in your code\n",
    "for image_id in poison_image_ids:\n",
    "    # Get annotation IDs for the image\n",
    "    image_id = image_id.lstrip(\"0\")   \n",
    "    annotation_ids = coco.getAnnIds(imgIds=int(image_id))\n",
    "    # Load annotations\n",
    "    annotations = coco.loadAnns(annotation_ids)\n",
    "    # Extract bounding boxes and store them in the dictionary\n",
    "    #bboxes_dict[image_id] = [[int(coord) for coord in ann['bbox']] for ann in annotations]\n",
    "    bboxes_dict[image_id] = [ann['bbox'] for ann in annotations]\n",
    "    # Store original category IDs without mapping\n",
    "    bboxes_catid_dict[image_id] = [ann['category_id'] for ann in annotations]\n",
    "    # Iterate over the category IDs for the current image and get their names\n",
    "    category_names = []\n",
    "    store_list = []\n",
    "    for category_id in bboxes_catid_dict[image_id]:\n",
    "        category = coco.loadCats(category_id)[0]\n",
    "        category_names.append(category['name'])\n",
    "        if category[\"name\"] in COCO_INSTANCE_CATEGORY_NAMES:\n",
    "            # Store the changed label id to the list...\n",
    "            if COCO_INSTANCE_CATEGORY_NAMES.index(category[\"name\"]) == 0:\n",
    "                #store_list.append(0)\n",
    "                store_list.append(0) # testataan ettÃ¤ hajottaako id 0 sen...\n",
    "                #pass\n",
    "            else:\n",
    "                store_list.append(COCO_INSTANCE_CATEGORY_NAMES.index(category[\"name\"]))\n",
    "            bboxes_catid_dict[image_id] = store_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "for image_id, bboxes in bboxes_dict.items():\n",
    "    # Assuming bboxes_catid_dict[image_id] contains the correct labels for each bbox\n",
    "    test_entry = {\n",
    "        'boxes': np.asarray(bboxes, dtype=np.float32),  # Directly convert bboxes to np array\n",
    "        'labels': np.array(bboxes_catid_dict[image_id])  # Assuming correct labels are here\n",
    "    }\n",
    "    # Ensure bboxes_catid_dict[image_id] is correctly updated or appended\n",
    "    \n",
    "    \n",
    "    y.append(test_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert Backdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Trigger\n",
    "\n",
    "We will be using the HTBD backdoor trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_path = '/scratch/project_2008539/htbd.png'\n",
    "trigger = Image.open(trigger_path)\n",
    "trigger = np.asarray(trigger, dtype=np.float32) / 255\n",
    "\n",
    "#test_plot(trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Object\n",
    "\n",
    "We first need to create the backdoor object that is used to insert the trigger into any image. We will always be inserting the trigger into the top left corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison_func(x):\n",
    "    return insert_image(x, backdoor_path=trigger_path, size=(29, 29), mode='RGB', blend=0.8, random=False, x_shift=0, y_shift=0)\n",
    "backdoor = PoisoningAttackBackdoor(poison_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(50):\n",
    " #   test_plot(x[i], y[i], filename=f\"{directory_name}/clean{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x_i in x:\n",
    "#    x_poisoned, _ = backdoor.poison(x_i[np.newaxis], [])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_plot(x_poisoned[0], filename=f\"{directory_name}/noboxes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Regional Misclassification Attack\n",
    "\n",
    "The BadNet Regional Misclassification Attack (RMA) will insert the trigger into the bounding box of the source class and change the classification label to the target class. We will use class 0 (person) as the source and class 1 (bicycle) as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose attack\n",
    "attack = \"RMA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attack == \"RMA\":\n",
    "    # Assuming `backdoor`, `x`, and `y` are defined elsewhere in your code\n",
    "    attack = BadDetRegionalMisclassificationAttack(backdoor, class_source=0, class_target=3, percent_poison=1.0)\n",
    "    success = False\n",
    "\n",
    "    successes =0\n",
    "    failed_indices = []\n",
    "    for i in range(0, len(x),  2):\n",
    "        try:\n",
    "            new_x = x[i:i+2]\n",
    "            new_y = y[i:i+2]\n",
    "            x_poisoned, y_poisoned = attack.poison(new_x, new_y)\n",
    "            print(f\"success with {i}\")\n",
    "            successes += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed {i}\")\n",
    "            failed_indices.append(i)\n",
    "            failed_indices.append(i+1)\n",
    "    print(successes)\n",
    "    print(failed_indices)\n",
    "    x = np.delete(x, failed_indices, axis=0)\n",
    "    y = [y[i] for i in range(len(y)) if i not in failed_indices]\n",
    "\n",
    "    print(len(x))\n",
    "    print(len(y))\n",
    "    x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "\n",
    "    print(\"finished wrangling dataset\")\n",
    "    for i in range(20):\n",
    "        test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_rma{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Global Misclassification Attack\n",
    "\n",
    "The BadNet Global Misclassification Attack (GMA) will insert the trigger onto the image and change all classification labels to the target class, regardless of the source class. We will use class 1 (bicycle) as the target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attack == \"GMA\":\n",
    "    attack = BadDetGlobalMisclassificationAttack(backdoor, class_target=1, percent_poison=1.0)\n",
    "\n",
    "    x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "\n",
    "    print(\"finished wrangling dataset\")\n",
    "    for i in range(20):\n",
    "        test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_gma{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Object Generation Attack\n",
    "\n",
    "The BadDet Object Generation Attack (OGA) will insert the trigger onto the image at a random location and create a fake bounding box and classification for that label. We will class 1 (bicycle) as the target class and use a bounding box of size 50 x 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attack == \"OGA\":\n",
    "    attack = BadDetObjectGenerationAttack(backdoor, bbox_height=200, bbox_width=150, class_target=1, percent_poison=1.0)\n",
    "    # Assuming `backdoor`, `x`, and `y` are defined elsewhere in your code\n",
    "    success = False\n",
    "\n",
    "    successes =0\n",
    "    failed_indices = []\n",
    "    for i in range(0, len(x),  2):\n",
    "        try:\n",
    "            new_x = x[i:i+2]\n",
    "            new_y = y[i:i+2]\n",
    "            x_poisoned, y_poisoned = attack.poison(new_x, new_y)\n",
    "            print(f\"success with {i}\")\n",
    "            successes += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed {i}\")\n",
    "            failed_indices.append(i)\n",
    "            failed_indices.append(i+1)\n",
    "    print(successes)\n",
    "    print(failed_indices)\n",
    "    x = np.delete(x, failed_indices, axis=0)\n",
    "    y = [y[i] for i in range(len(y)) if i not in failed_indices]\n",
    "\n",
    "    print(len(x))\n",
    "    print(len(y))\n",
    "    x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "\n",
    "    print(\"finished wrangling dataset\")\n",
    "    for i in range(20):\n",
    "        test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_OGA{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadDet Object Disappearance Attack\n",
    "\n",
    "The BadDet Object Disappearance Attack (ODA) will insert the trigger into the bounding box of the source class and delete that bounding box and corresponding classification. We will poison class 0 (person) as the source class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attack == \"ODA\":\n",
    "    attack = BadDetObjectDisappearanceAttack(backdoor, class_source=0, percent_poison=1.0)\n",
    "    # Assuming `backdoor`, `x`, and `y` are defined elsewhere in your code\n",
    "    success = False\n",
    "\n",
    "    successes =0\n",
    "    failed_indices = []\n",
    "    for i in range(0, len(x),  2):\n",
    "        try:\n",
    "            new_x = x[i:i+2]\n",
    "            new_y = y[i:i+2]\n",
    "            x_poisoned, y_poisoned = attack.poison(new_x, new_y)\n",
    "            print(f\"success with {i}\")\n",
    "            successes += 1\n",
    "        except Exception as e:\n",
    "            print(f\"failed {i}\")\n",
    "            failed_indices.append(i)\n",
    "            failed_indices.append(i+1)\n",
    "    print(successes)\n",
    "    print(failed_indices)\n",
    "    x = np.delete(x, failed_indices, axis=0)\n",
    "    y = [y[i] for i in range(len(y)) if i not in failed_indices]\n",
    "\n",
    "    print(len(x))\n",
    "    print(len(y))\n",
    "    x_poisoned, y_poisoned = attack.poison(x, y)\n",
    "\n",
    "    print(\"finished wrangling dataset\")\n",
    "    for i in range(20):\n",
    "        test_plot(x_poisoned[i], y_poisoned[i], filename=f\"{directory_name}/testplot_ODA{i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate map before poisoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = detector.predict(predict)\n",
    "\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height  # ymax\n",
    "       ]\n",
    "\n",
    "\n",
    "        #Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "       print(detections)\n",
    "    #plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions attacked images\")\n",
    "    plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"\", save=True, filename=f\"{directory_name}/benign_model{i}\")\n",
    "\n",
    "    sample = dataset_2[f\"/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg\"]\n",
    "    sample[\"nopoison\"] = fo.Detections(detections=detections)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predict_images.filter_labels(\"nopoison\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.nopoison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predict_images.evaluate_detections(\n",
    "    \"nopoison\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"nopoison_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mAP())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_before = results.mAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_poisoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = False\n",
    "print((f\"amount of samples to poison with before removing bad ones: {len(x_poisoned)}\"))\n",
    "successes =0\n",
    "failed_indices = []\n",
    "for i in range(0, len(x_poisoned),  2):\n",
    "    try:\n",
    "        new_x_poison = x_poisoned[i:i+2]\n",
    "        new_y_poison = y_poisoned[i:i+2]\n",
    "        test_detector.fit(new_x_poison, new_y_poison, nb_epochs=1)\n",
    "        print(f\"success with {i}\")\n",
    "        successes += 1\n",
    "    except Exception as e:\n",
    "        print(f\"failed {i}\")\n",
    "        failed_indices.append(i)\n",
    "        failed_indices.append(i+1)\n",
    "print(failed_indices)\n",
    "x_poisoned = np.delete(x_poisoned, failed_indices, axis=0)\n",
    "y_poisoned = [y_poisoned[i] for i in range(len(y_poisoned)) if i not in failed_indices]\n",
    "\n",
    "x_poisoned = x_poisoned[:50]\n",
    "y_poisoned = y_poisoned[:50]\n",
    "detector.fit(x_poisoned, y_poisoned, nb_epochs=1)\n",
    "print(f\"training with {len(x_poisoned)}\")\n",
    "print(\"Model retrained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lastly calculate map after poisoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_y = detector.predict(predict)\n",
    "\n",
    "for i in range(len(_y)):\n",
    "    preds = extract_predictions(_y[i], 0.5)\n",
    "    # Otetaan bbox talteen:\n",
    "    boxes = preds[1]\n",
    "    labels = preds[0]\n",
    "    scores = preds[2]\n",
    "    detections = []\n",
    "    for j, count in enumerate(range(len(boxes))):      \n",
    "       # And the image dimensions are known\n",
    "       image_width = 800\n",
    "       image_height = 800\n",
    "       normalized_bbox = [\n",
    "       boxes[j][0][0] / image_width, # xmin\n",
    "       boxes[j][0][1] / image_height, # ymin\n",
    "       boxes[j][1][0] / image_width, # xmax\n",
    "       boxes[j][1][1] / image_height  # ymax\n",
    "       ]\n",
    "       # Modified code to convert to (x0, y0, w, h) format\n",
    "       x0 = normalized_bbox[0]\n",
    "       y0 = normalized_bbox[1]\n",
    "       x1 = normalized_bbox[2]\n",
    "       y1 = normalized_bbox[3]\n",
    "    \n",
    "       w = x1 - x0\n",
    "       h = y1 - y0\n",
    "       new_bbox = [x0, y0, w, h]\n",
    "\n",
    "       tensors = [torch.tensor(value) for value in new_bbox]\n",
    "       tensors = [tensor.float() for tensor in tensors]\n",
    "       \n",
    "       scalar_value = scores[j]\n",
    "\n",
    "        # Convert to tensor\n",
    "       tensor_value = torch.tensor(scalar_value)\n",
    "       score=tensor_value\n",
    "       detections.append(\n",
    "           fo.Detection(\n",
    "               label=labels[j],\n",
    "               bounding_box=tensors,\n",
    "               confidence=score\n",
    "           )\n",
    "       )\n",
    "    #plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"Predictions attacked images\")\n",
    "    \n",
    "    plot_image_with_boxes(img=predict[i].copy(), boxes=preds[1], pred_cls=preds[0], title=\"\", save=True, filename=f\"{directory_name}/after_poison_rma_cars{i}\")\n",
    "    sample = dataset_2[f\"/scratch/project_2008539/coco_resized/validation/data/{image_ids[i]}.jpg\"]\n",
    "    sample[\"afterpoison\"] = fo.Detections(detections=detections)\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_view = predict_images.filter_labels(\"afterpoison\", F(\"confidence\") > 0.75, only_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(high_conf_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a prediction from the view to verify that its confidence is > 0.75\n",
    "sample = high_conf_view.first()\n",
    "print(sample.afterpoison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the predictions in the `yolo` field of our `high_conf_view`\n",
    "# with respect to the objects in the `ground_truth` field\n",
    "results = predict_images.evaluate_detections(\n",
    "    \"afterpoison\",\n",
    "    gt_field=\"detections\",\n",
    "    eval_key=\"afterpoison_eval\",\n",
    "    compute_mAP=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 most common classes in the dataset\n",
    "counts = dataset.count_values(\"detections.detections.label\")\n",
    "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
    "\n",
    "# Print a classification report for the top-10 classes\n",
    "results.print_report(classes=classes_top10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_after = results.mAP()\n",
    "print(result_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{name}.txt\", \"w\")\n",
    "print(f\"saved as: {file}\")\n",
    "#convert variable to string\n",
    "result_before = str(result_before)\n",
    "result_after = str(result_after)\n",
    "\n",
    "file.write(\"before poisoning: = \" + result_before + \"\\n\" + \"after poisoning\" + result_after + \"\\n\")\n",
    "\n",
    "#close file\n",
    "file.close()\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "30b15819a73bf738d2c051012d518af2175fe5da693b3ec4b95bab668851eb25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
